import pandas = pandas 

index = row
columns = column

dataset = pandas.read_csv('csv_file') = show csv_file

dataset.head(5) = get first 5 item

dataset.tail(5) = get last 5 item

dataset.to_csv('file_name.csv', index=False) = copy csv file

dataset.to_excel('file_name.xlsx', index=False, sheet_name="") = copy to excel file

pandas.read_excel('file_name.xlsx', sheet_name="") = show excel file

pandas.read_html('url') = read file html file

machine = create_engine('sqlite:///:memory:') = create mysql engine
dataset.to_sql('file_name', con=machine) = create to sql file
pandas.read_sql('file_name', con=machine)

pandas.options.display.max_rows = 891 = set to display all item
pandas.options.display.min_rows = 891 = set to display all item
pandas.set_option('display.min_rows', None) = show all rows

dataset.info() = show column data type

dataset.describe() = show math data
dataset.transpose() = change view table (column to row / row to column)

dataset.column_name = get row by column
dataset['column_name'] = get row by column
dataset[['column_name']] = get row by column
dataset[['column_name', 'column_name']] = get row by 2 column

dataset['column_name'].equals(dataset['column_name']) = check is same

dataset[column_name].str[0:2] = slicing column value

dataset[dataset[column_name] (action)] = filtering column and get full row

all_data[all_data.index == 356] = get full row on index

dataset.iloc[:] = slicing
dataset.iloc[1:4, 2:4] = slicing rows & cols
dataset.iloc[[1, 2, 4], [2, 3, 4]] = slicing rows & cols

dataset.loc[1, 'column_name'] = get value by row & column
dataset.loc['S'] = get all value with 'S'
dataset.loc['S', ['name', 'age']] = get name, age with value with 'S'

dataset.any(axis) = check if row / column have True

s = pandas.Series(key, value) = list to series
s[index]s = get first value
s[0] = get first value
s.to_frame = show table series

dataset = pandas.dataset(data, index=[], column=[]) # create table (dict dtype)
dataset = pandas.dataset({
    'column_name': [value, value, value]
}, index=["key_name", "key_name", "key_name"])

dataset[new_column_name] = dataset[column_name] # create new column with exists column

dataset.drop(column_name, axis=1) = delete column and row
dataset.drop(column_name, axis=1, inplace=True) = delete column and row permanently
dataset.drop('row_name', axis=0, inplace=True) = delete row permanently

dataset[new_column_name] = value # create new column with same value

dataset[column_name].isnull() = set column value as NaN / Null
dataset[dataset[column_name].notnull()] = find value that not null
dataset.dropna(subset=[column_name], axis=0) = drop column that null 

dataset.count() = count value on column

dataset.groupby(column_name).count() = count value by column_name

dataset.shape = (row.length, column.length)

dataset.drop_duplicates(subset=[column_name, column_name]) = remove row on duplicate value in 2 column

dataset[column_name].dropna() = remove N/A
dataset.dropna(subset=[column_name]) = remove N/A
dataset[column_name].fillna(new_value) = replace N/A 
dataset.isna() = check each column value if NaN
dataset[dataset.isna().any(axis=1)] = get null from column in dataset

dataset.set_index(column_name) = create new index from column name
dataset.reset_index(drop=True) = reset index

dataset[column_name].apply(func) = function action into column / row value
dataset[column_name].transform(func) = function action into column / row value

dataset[~dataset[column_name] > 50] = contrast below than 50

dataset[column_name].value_counts() = count duplicated value length 

dataset.age.values = get all value in column 

sum(dataset[column_name]) = sum all value in column

dataset[dataset[column_name].duplicated(keep=False)] = Sort duplicated By column_name

pandas.dataset(data[column_name].head().str.slice(0, 3)) # get 3 letter of column value

dataset[column_name].dt.hour/minute/second = get Hour / Minutes / Second in column

dataset.query("column_name > 5") = filter value in column
dataset[dataset[column_name.isin([value in column])]] = find value in column

pandas.concat([dataset1, dataset2, ...], axis=0) = concat datasets (row)
pandas.concat([dataset1, dataset2, ...], axis=1) = concat datasets (column)
pandas.concat([dataset1, dataset2, ...], axis=1, join="inner") = inner = remove Nan Row take Notnull row

pandas.merge(dataset1, dataset2) = merging 2 column and value same to 1 column
pandas.merge(dataset1, dataset2, how="left", on="[column1, column2]") = merging matching the left
pandas.merge(dataset1, dataset2, how="right", on="[column1, column2]") = merging matching the right
pandas.merge(dataset1, dataset2, how="outer", on="[column1, column2]") = merging both (insert both)
pandas.merge(dataset1, dataset2, how="inner", on="[column1, column2]") = merging only matching row
pandas.merge(dataset1, dataset2, left_on="column1", right_on="column2") = merging follow same value in column

dataset1.join(dataset2) = join follow the index follow dataset1
dataset1.join(dataset2, how="inner") = join (only matching index)

===== CRUD =====

# CREATE

data = ["A", "B", "C", "D", "E"] = column value
column = { "Letters": data } = column name
index = numpy.arange(len(data)) = index
pandas.dataset(column, index)

# READ

dataset1[["column_name", "column_name"]] = show value in more columns
dataset1.loc[0] = get first data
dataset1.iloc[0] = get first data
dataset1.iloc[0:5] = slicing
dataset.head(5) = get first 5 data
dataset.tail(5) = get last 5 data
dataset[dataset[column_name] == value] = get row with the same value
dataset[dataset[column_name] > value] = get row with higher than 5
pandas.dataset["column_name"] = get all value in column

# UPDATE

dataset.rename(columns={ "selected_column" : "new_column_name" }) = rename column name
dataset[index, column_name] = "new_value" = update 1 value in row
dataset["column_name"].replace(value, new_value) = update all related value

# DELETE

dataset.drop(0) = delete first row
dataset.drop(index=row_number) = delete index
dataset.drop(["index", "index"]) = delete 2 row
dataset.drop(dataset[dataset["column_name"] == "find_value"].index) = delete more row
dataset.drop(columns="column_name") = delete column & value
dataset.drop(columns="{column_name, column_name}") = delete more column

===== Filter =====

dataset[dataset[column_name] > value] = find row higher than value
dataset.loc[:] = slicing row

===== Sorting ===== 

dataset.sort_values("column_name", ascending=True) = sorting smaller to greater on column
dataset.sort_values("column_name", ascending=False) = sorting greater to smaller on column
dataset.iloc[::-1] = reverse dataset

===== Grouping ===== 

dataset.groupby(column_name) = filtering difference value in column (for loop)

===== Merging ===== 